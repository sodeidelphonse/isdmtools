---
title: "ISDM Evaluation Workflow"
date: "Generated on `r Sys.Date()`"
author: "Akoeugnigan Idelphonse SODE"
bibliography: ../inst/REFERENCES.bib
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ISDM Evaluation Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7, 
  fig.height = 5,
  eval = TRUE
)
```

```{r warning=FALSE,message=FALSE}
library(isdmtools)
library(sf)
library(terra)
library(fmesher)
library(ggplot2)
library(inlabru)
#library(INLA)  # required
```

# Introduction
As demonstrated in the [Home page](../index.html) and [Get started](isdmtools.html) guides, the first output from the `isdmtools` package is a set of clean `sf` objects, which makes it easy to integrate with various spatial modeling tools using block cross-validation techniques. The extracted training and testing data can be directly fed into your preferred integrated modeling tools such as `inlabru`, `PointedSDMs`, or any `GLMs/GAMs` tools that can accommodate multisource spatial data. This ensures that your model predictions are validated using a robust spatial cross-validation approach and comprehensive evaluation metrics. 

This vignette shows how how the `isdmtools` can be used with other predictive modelling tools such as `inlabru` for a complete workflow of integrated species distribution modelling (ISDM) analysis.

# Fitting an integrated model with `inlabru` 

The `inlabru` package [@bachl_inlabru_2019] is a wrapper for the `R-INLA` [@rue_approximate_2009]  which is designed for Bayesian Latent Gaussian Modelling using Integrated Laplace Nested Approximations (INLA) and Extensions. Let us develop a Bayesian spatial model with the simulated data resampled for cross-validation as demonstrated in the guide on the [Home page](../index.html). 

## Step 1: Model definition

We assume the following basic joint model with a shared latent signal $\xi(.)$ represented by a Gaussian random field with a *Matern* correlation function:

$$
 \begin{aligned} 
 Y_{\mathrm{count},i}|\xi(.)&\sim\!\mathrm{Pois} \left(\mu_i \right), \quad i = 1,\ldots,n,\\
 \log(\mu_i)&=\!\beta_{0,\mathrm{count}} + \xi(\mathbf{s}_i)\\[2mm]
 X_{\mathrm{presence}}|\xi(.)&\sim\!\mathrm{IPP} \left(\lambda(\mathbf{s}) \right),\\
\log (\lambda(\mathbf{s}))&=\!\beta_{0,\mathrm{presence}} + \xi(\mathbf{s})\\
\end{aligned}
$$
where $\mathrm{IPP}$ means a _Inhomogeneous Poisson Process_ and $\mathbf{s}$ the vector of a location coordinates. The IPP model presented here is known in spatial statistics as a log-Gaussian Cox process model - LGCP (see, @moller_log_1998) . Although the large-scale component which includes the data-specific intercept can also incorporate environmental covariates, we assume that the basic joint model above is valid for the data. Alternative specifications of data fusion model have been discussed in @sode_integrating_2025. 

## Step 2: Model implementation

You can now prepare the remaining data required to fit an integrated model. First, we need to define the study region and set up the mesh to be used for approximating the latent field as well as for the integration points in the LGCP likelihood.

```{r }
# Define the study region (e.g. Benin's boundary rectangle)
ben_coords <- matrix(c(0, 6, 4, 6, 4, 13, 0, 13, 0, 6), ncol = 2, byrow = TRUE)
ben_sf <- st_sf(data.frame(name = "Region"), 
                          st_sfc(st_polygon(list(ben_coords)), 
                          crs = 4326))
```


```{r mesh-code, fig.width = 3, fig.height = 4, out.width = "80%", eval = exists("ben_sf")} 
# Create a "mesh" for the latent field 
mesh <- fmesher::fm_mesh_2d(
     boundary = ben_sf,
     max.edge = c(0.2, 0.5),
     offset = c(1e-3, 0.6),
     cutoff = 0.10,
     crs = "epsg:4326"
)
ggplot() + inlabru::gg(mesh)
```

After this step, we set up the prior distributions for the latent parameters such as the range and the marginal standard deviation, keeping default prior for the intercepts. we define the prior distribution for the model hyperparameters using the penalized model component complexity priors (see @simpson_penalising_2017 for more details). Then we define the observation model for each data type and fuse them using a joint likelihood estimation with INLA and SPDE techniques [@simpson_going_2016].

```{r modeling, eval = requireNamespace("INLA", quietly = TRUE) && exists("train_data")}
# Set the PC-prior for the SPDE model. We estimate a longer range value as no spatial 
# autocorrelation was defined in the data generation process:
pcmatern <- INLA::inla.spde2.pcmatern(mesh,
                                      prior.range = c(1, 0.1), # Prob(spatial range < 1) = 0.1
                                      prior.sigma = c(1, 0.1)  # Prob(sigma > 1) = 0.1
                                      )
   
# The shared spatial latent component is denoted by 'spde'
jcmp <- ~ -1 + Presence_intercept(1) + Count_intercept(1) +
                  spde(geometry, model = pcmatern)
   
# Count observation model
obs_model_count <- inlabru::bru_obs(
     formula = count ~  + Count_intercept + spde,
     family = "poisson",
     data = train_data$Count
 )
   
# Presence-only observation model (LGCP)
obs_model_pres <- inlabru::bru_obs(
     formula = geometry ~ Presence_intercept + spde,
     family = "cp",
     data = train_data$Presence,
     domain = list(geometry = mesh),
     samplers = list(geometry = ben_sf)
)
   
# Model fit
jfit <- inlabru::bru(jcmp, obs_model_count, obs_model_pres,
                        options = list(control.inla = list(int.strategy = "eb"),
                                       bru_max_iter = 20)
                    )
```

We can collect model results after the fitting process.

```{r results, eval = FALSE}
 jfit$summary.fixed
 #>                     mean        sd      0.025quant  0.5quant   0.975quant  mode      kld
 #> Count_intercept    -0.2497590 0.3086958 -0.8547916 -0.2497590  0.3552737  -0.2497590  0
 #> Presence_intercept  0.9269141 0.2836352  0.3709992  0.9269141  1.4828289   0.9269141  0
 #>  
 jfit$summary.hyperpar
 #>                mean        sd      0.025quant  0.5quant   0.975quant  mode
 #> Range for spde 3.535334 2.5240208  0.9513318   2.8572241  10.2509603  1.9527898
 #> Stdev for spde 0.512346 0.1926203  0.2183487   0.4842595  0.9647017   0.4317979
``` 

As expected, the estimated _spatial range_ is higher than 1. This is because there is no strong spatial autocorrelation in the simulated data.
 
## Step 3: Model prediction 

```{r grids, eval = exists("mesh")} 
# Define the prediction grids and projection system
grids      <- fmesher::fm_pixels(mesh, mask = ben_sf)
projection <- "+proj=longlat +ellps=WGS84 +datum=WGS84"
```

```{r jpred, eval = exists("jfit")} 
# Model predictions
jpred <- predict(jfit, 
                 newdata = grids, 
                 formula = ~ spde + Presence_intercept,
                 n.samples = 500, 
                 seed = 24)

jpred_count <- predict(jfit, 
                       newdata = grids, 
                       formula = ~ spde + Count_intercept ,
                       n.samples = 500, 
                       seed = 24)
```

# Suitability analysis and model evaluation with `isdmtools`

## Step 4: Habitat suitability analysis

Once we have obtained the model predictions, we can then use the `isdmtools` to perform habitat suitability analysis. This will allow us to proceed with the evaluation of models and the visualisation of results. 

```{r jt-prob, eval = exists("jpred")}
# Probability of presence
jpred   <- prepare_predictions(jpred) 
jt_prob <- suitability_index(jpred, 
                            post_stat = c("q0.025", "mean", "q0.975"), 
                            output_format = "prob",
                            response_type = "joint.po",
                            projection = projection,
                            scale_independent = TRUE
                            )
plot(jt_prob)
```

```{r jt-count, eval = exists("jpred_count")}
# Expected counts
jpred_count <- prepare_predictions(jpred_count)
jt_count <- suitability_index(jpred_count, 
                              post_stat = c("q0.025", "mean", "q0.975"), 
                              output_format = "response",
                              response_type = "count",
                              projection = projection
                              )
plot(jt_count)
```
 
## Step 5: Model performance evaluation 

Various performance metrics can now be computed, including dataset-specific and weighted composite scores using the test data and model predictions. As you will notice, certain arguments to the suitability_index() function are left at their default values. Specifically, this concerns the number of background points, the threshold method (which is "best"), and the best method (which is "youden"). The latter is the *Youden* criterion, which corresponds to the threshold that maximises both sensitivity and specificity.

```{r evaluation,  eval = FALSE}
 xy_observed <- rbind(st_coordinates(datasets_list$Presence)[, c("X","Y")], 
              st_coordinates(datasets_list$Count)[datasets_list$Count$count > 0, c("X","Y")])
   
 metrics <- c("auc", "tss", "accuracy", "rmse", "mae")
 eval_metrics <- compute_metrics(test_data, 
                                prob_raster = jt_prob$mean, 
                                expected_response = jt_count$mean,
                                xy_excluded = xy_observed, 
                                metrics = metrics,
                                overall_roc_metrics = c("auc", "tss", "accuracy"),
                                response_counts = "count"
                                )
print(eval_metrics)

#> ISDM Model Evaluation Results
#> ----------------------------------------------
#> Datasets Evaluated: Presence, Count 

#> Overall Performance:
#>  TOT ROC SCORE     : 0.8048
#>  TOT ERROR SCORE   : 1.9353
#> ----------------------------------------------
```

One can obtain detailed overview of the evaluation results via the `summary()` method. 

```{r metric, eval = FALSE}
summary(eval_metrics)

#> ==============================================
#>        ISDM EVALUATION SUMMARY REPORT
#> ==============================================
#> Generated on: 2026-01-19 04:41:02 

#> --- Model Evaluation Settings ---
#> Random Seed         : 25
#> Background Points   : 1000
#> Spatial Context     : BackgroundPoints object attached
#> Threshold Logic     : best
#> Optimality Criterion: youden
#> Prediction Type     : Absolute Count (No Offset)

#> --- Detailed Metric Table ---
#>         Presence Count
#> AUC         0.917 0.750
#> TSS         0.791 0.750
#> ACCURACY    0.794 0.778
#> RMSE          N/A 2.119
#> MAE           N/A 1.752

#> --- Composite Scores (Weighted) ---
#>     AUC      TSS ACCURACY     RMSE      MAE 
#>    0.852    0.775    0.788    2.119    1.752 

#> --- Overall Performance ---
#>  TOT ROC SCORE     : 0.8048
#>  TOT ERROR SCORE   : 1.9353
#> ==============================================
```

As you will have noticed, continuous-outcome metrics such as MAE (mean absolute error) and RMSE (root mean squared error) are not available for presence-only data, which makes sense. Furthermore, the weighted composite scores for continuous responses are identical to their individual counterparts, since there is only one count response. Moreover, you can check out the [`get_background()`](../reference/get_background.html) documentation for more details on background sample generated during the model evaluation.

Next, you can iterate through all five spatial folds to obtain an average model performance, then calculate the variation in metrics between blocks. Finally, you should run a model on the full data (i.e. 'datasets_list') in order to make the final prediction.
 
## Step 6: Prediction mapping 

You can now generate a formal prediction map ready for publication. Assume that the probability of the species presence is stored in the object 'jt_prob' after the final model fitting.

```{r maps, eval = exists("jt_prob")}
map <- generate_maps(jt_prob, 
                   var_names = c("q0.025", "mean", "q0.975"), 
                   base_map = ben_sf,
                   legend_title = "suitability",  
                   panel_labels = c("(a) q2.5%", "(b) Mean", "(c) q97.5%"),
                   xaxis_breaks = seq(0, 4, 1),
                   yaxis_breaks = seq(6, 13, 2)
                   )
map
```

```{r, echo=FALSE, out.width="100%", fig.cap="Prediction map of the ISDM model"}
knitr::include_graphics("../man/figures/prediction_map.png")
```

# Conclusion

You have successfully fused multi-source biodiversity data and generated spatially independent partitions for robust model validation using `isdmtools`. The toolkit has enabled the *resampling of data*, thereby reducing *spatial autocorrelation* effects in the modelling process. It has also facilitated the analysis and a comprehensive evaluation of ISDM using well-known metrics from the fields of statistics and machine learning.

# References
