---
title: "Get started"
date: "Generated on `r Sys.Date()`"
author: "Akoeugnigan Idelphonse SODE"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)
```

```{r warning=FALSE,message=FALSE}
library(isdmtools)
library(sf)
library(terra)
library(dplyr)
library(ggplot2)
```

# Introduction

This vignette should bridge the gap between "having spatial data" and "being ready for modelling." The fundamental philosophy of `isdmtools` is to provide a standardised bridge between diverse biodiversity spatial data sources and a robust spatial cross-validation (CV) strategy for evaluating integrated species distribution models (ISDMs). This tutorial will assist you through preparing data and generating spatial folds â€” the essential first steps before fitting an Integrated Species Distribution Model (ISDM).

# Data Preparation

## Step 1: Simulate some spatial data

Let's consider a simple scenario by generating two spatial datasets representing the presence and abundance of a given species within a designated study region. The purpose of this tutorial is to provide a simple introduction to the tool, as opposed to addressing a very complex scenario of spatially autocorreleted datasets.

```{r }
# Simulate a list of presence-only and count data
set.seed(42)
presence_data <- data.frame(
  x = runif(100, 0, 4), 
  y = runif(100, 6, 13), 
  site = rbinom(100, 1, 0.6)
) %>% st_as_sf(coords = c("x", "y"), crs = 4326)

count_data <- data.frame(
  x = runif(50, 0, 4), 
  y = runif(50, 6, 13), 
  count = rpois(50, 5)
) %>% st_as_sf(coords = c("x", "y"), crs = 4326)

datasets_list <- list(Presence = presence_data, Count = count_data)

# Define the study region (e.g. Benin's boundary rectangle)
ben_coords <- matrix(c(0, 6, 4, 6, 4, 13, 0, 13, 0, 6), ncol = 2, byrow = TRUE)
ben_sf <- st_sf(data.frame(name = "Region"), 
                          st_sfc(st_polygon(list(ben_coords)), 
                          crs = 4326))
                          
# Gnerate some continuous covariates
set.seed(42)
r   <- rast(ben_sf, nrow = 100, ncol = 100)
r[] <- rnorm(ncell(r))
rtmp   <- r
rtmp[] <- runif(ncell(r), 5, 10)

r <- c(r, rtmp + r)
names(r) <- c("cov1", "cov2")
```

## Step 2: Spatial Partitioning

Partitioning spatial data into spatial folds is important since it helps reduce spatial autocorrelation in the observations and estimate a more realistic model performance.

```{r }
# Create the DataFolds object using the default method
folds <- create_folds(datasets_list, ben_sf, cv_method = "cluster")
```

```{r fold-plot, fig.width = 6, fig.height = 6, out.height= "100%", fig.align = "center"}
# Visualize the folds with custom styling
plot(folds, nrow = 2, annotate = FALSE) +
  scale_x_continuous(breaks = seq(0, 4, 1)) +
  scale_y_continuous(breaks = seq(6, 13, 2)) +
  theme_minimal() +
  labs(title = "Spatial Block Partitioning")
```

```{r auto-plot, fig.width = 4, fig.height = 4, out.width = "100%", fig.align = "center"}
# Create the DataFolds object using the `spatialsample` blocking engine
fold_ss <- create_folds(datasets_list, ben_sf, cv_method = "block")

# Using the native autoplot of `spatialesample`
ggplot2::autoplot(fold_ss)
```

```{r }
# Folds summary
summary(fold_ss)
```

## Step 3: Folds diagnostics

Various diagnostic analyses can be performed on the folds that were created in the previous step. Specifically, if there is any prior information on the spatial range from an exploratory analysis, it can be used as a value for the `rho` argument of the `check_folds()`' method. This value can then be compared to the calculated inter-fold gap in order to ascertain whether folds are independent. For instance, the `blockCV::cv_spatial_autocor()` function can help derive prior information on the spatial range. The same procedure can be applied to a Bayesian analysis to check if the posterior range estimated aligns with the spatial geometry of the specified folds or blocks. 

* **Folds diagnostics in geographical space**

```{r geo-diag, fig.width = 5, fig.height = 5, out.width = "90%"}
# Check spatial independence of folds using default rho (N/A)
# Type ?check_folds for more details on the method
geo_diag <- check_folds(folds, plot = TRUE)
print(geo_diag)

# Plot results
plot(geo_diag) 

```

As the summary information illustrates, the minimum distance between points within a specific block (or fold) and its nearest block (i.e., the inter-block gap) is approximately 42 km. This indicates that there is no contiguous spatial folds from the selected blocking strategy, thereby supporting the hypothesis of no *block leakage*.

* **Folds diagnostics in the environmental space**

```{r warning=FALSE,message=FALSE}
# Check environmental balance of folds
set.seed(42)  # for background sample reproducibility
env_diag <- check_env_balance(folds,
                              covariates = r,
                              n_background = 5000
                              )
print(env_diag)

```

```{r env-diag, fig.width = 6, fig.height = 4, out.width = "100%"}
# Plot outputs
plot(env_diag)

```

As illustrated in the summary table, the Schoener D metric is greater than 0.6 for both covariates. This indicates that spatial folds exhibit significant overlap with the background area. Consequently, it can be posited that the blocks are environmentally representative.

* **Combined analysis**

It is possible to combine both types of fold diagnostics in order to draw a unified conclusion. However, it should be noted that the applicability of both diagnostic tools is not universal across all the spatial blocking strategies covered in the package. Therefore, the most appropriate diagnostic tool may be contingent on the selected blocking scheme.

```{r }
# Combined diagnostics
summarise_fold_diagnostics(geo_diag, env_diag)

```

## Step 4: Data Extraction for Modelling

Once spatial folds are created, one can extract the data and see how it looks like right 
before it goes into a modelling tool like inlabru. You can access both 'train' and 'test' sets and their corresponding datasets as follows:

```{r }
# Extract fold 1
splits_1 <- extract_fold(folds, fold = 1)

# Accessing the training and testing sets for the "Presence" source
head(splits_1$train$Presence)

head(splits_1$test$Presence)
```

# Conclusion

Congratulations! You have successfully fused multi-source biodiversity data and generated spatially independent partitions for robust model validation. By using `create_folds()` and related folds' diagnostic tools, you've ensured that your model evaluation will account for spatial autocorrelation, providing a more realistic estimate of predictive performance. 

The `isdmtools` journey continues with model fitting and comprehensive evaluation. Depending on your needs, we recommend the following paths:

- *Model Fitting*: Use the training data extracted via `extract_fold()` to fit your models using modelling engines like inlabru, PointedSDMs, or standard GAMs tools which can support multisource spatial data.
- *Integrated Evaluation*: Once predictions are obtained, evaluate the models and analyse the outputs.

The advanced guide on [ISDM Evaluation Workflow](isdm-workflow.html) covers model building with external tools, calculation of dataset-specific and composite scores, suitability analysis and mapping with `isdmtools`.

