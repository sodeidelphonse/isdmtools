---
title: "Get started with isdmtools"
date: "Generated on `r Sys.Date()`"
author: "Akoeugnigan Idelphonse SODE"
bibliography: ../inst/REFERENCES.bib
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)
```

```{r warning=FALSE,message=FALSE}
library(isdmtools)
library(sf)
library(terra)
library(dplyr)
library(ggplot2)
```

# Introduction

The integrated species distribution modelling (ISDM) is any statistical approach that combine biodiversity data from different sampling schemes with the purpose of correcting for biases or providing an overall estimation of the species distribution based on multisource evidence. This vignette should bridge the gap between "having spatial data" and "being ready for modelling." The fundamental philosophy of `isdmtools` is to provide a standardised bridge between diverse biodiversity spatial data sources and a robust spatial cross-validation (CV) strategy for evaluating integrated species distribution models (ISDMs). This tutorial will assist you through preparing data and generating spatial folds — the essential first steps before fitting an Integrated Species Distribution Model (ISDM).

# Data Preparation

Let's consider a simple scenario by generating two spatial datasets representing the presence and abundance of a given species within a designated study region. The purpose of this tutorial is to provide a simple introduction to the tool, as opposed to addressing a very complex scenario of spatially autocorreleted datasets.

```{r }
# Simulate a list of presence-only and count data
set.seed(42)
presence_data <- data.frame(
  x = runif(100, 0, 4), 
  y = runif(100, 6, 13), 
  site = rbinom(100, 1, 0.6)
) %>% st_as_sf(coords = c("x", "y"), crs = 4326)

count_data <- data.frame(
  x = runif(50, 0, 4), 
  y = runif(50, 6, 13), 
  count = rpois(50, 5)
) %>% st_as_sf(coords = c("x", "y"), crs = 4326)

datasets_list <- list(Presence = presence_data, Count = count_data)

# Define the study region (e.g. Benin's boundary rectangle)
ben_coords <- matrix(c(0, 6, 4, 6, 4, 13, 0, 13, 0, 6), ncol = 2, byrow = TRUE)
ben_sf <- st_sf(data.frame(name = "Region"), 
                          st_sfc(st_polygon(list(ben_coords)), 
                          crs = 4326))
                          
# Generate some continuous covariates
set.seed(42)
r   <- rast(ben_sf, nrow = 100, ncol = 100)
r[] <- rnorm(ncell(r))
rtmp   <- r
rtmp[] <- runif(ncell(r), 5, 10)

r <- c(r, rtmp + r)
names(r) <- c("cov1", "cov2")
```

# Spatial Data Partitioning

The partitioning of spatial data into spatial folds is a crucial step in the process of model evaluation via blocked cross-validation, as it assists in the reduction of spatial autocorrelation in the observations. This, in turn, enables the estimation of a more realistic model performance. In the following code chunks, we illustrate two distinct blocking schemes for the purpose of dividing the observed spatial data.

```{r }
# Create the DataFolds object using the default method
folds <- create_folds(datasets_list, ben_sf, cv_method = "cluster")
```

```{r fold-plot, fig.width = 6, fig.height = 6, out.height= "100%", fig.align = "center"}
# Visualize the folds with custom styling
plot(folds, nrow = 2, annotate = FALSE) +
  scale_x_continuous(breaks = seq(0, 4, 1)) +
  scale_y_continuous(breaks = seq(6, 13, 2)) +
  theme_minimal() +
  labs(title = "Spatial Block Partitioning")
```

```{r auto-plot, fig.width = 4, fig.height = 4, out.width = "100%", fig.align = "center"}
# Create the DataFolds object using the `spatialsample` blocking engine
fold_ss <- create_folds(datasets_list, ben_sf, cv_method = "block")

# Using the native autoplot of `spatialesample`
ggplot2::autoplot(fold_ss)
```

```{r }
# Folds summary
summary(fold_ss)
```

# Folds Diagnostics

The `isdmtools` package introduces various *diagnostic tools* to perform supplementary analyses on the quality of the spatial folds (or blocks) that were created in the previous step. We distinguish between diagnostics in geographical and environmental spaces as well as combined analyses. The *geographical fold diagnostics* are performed using the `check_folds()` method while the *environmental fold diagnostic* is achieved via the `check_env_balance()` method. Depending on the spatial blocking strategy used for data partitioning, both diagnostic analyses can be combined into a unified framework. The The following sections introduces each diagnostic tools to assess the validity of spatial folds generated for blocked cross-validation.

For *geographical fold diagnostics*, if there is any prior information on the spatial range from an exploratory analysis, it can be used as a value for the `rho` argument of the `check_folds()`' method. This value can then be compared to the calculated inter-fold gap in order to ascertain whether folds are independent. For instance, the `blockCV::cv_spatial_autocor()` function can help derive prior information on the spatial range [@valavi_blockcv_2018]. Additionally, if the correlation function is part of *Matérn* family, the helper function `solve_practical_range()` from the `isdmtools` package can help derive the corresponding *practical range* needed for the spatial diagnostics (see @sode_integrating_2025 for more details). The same procedure applies to a Bayesian analysis to check if the posterior range estimated aligns with the spatial geometry of the specified folds. 

* **Folds diagnostics in geographical space**

```{r geo-diag, fig.width = 5, fig.height = 5, out.width = "90%"}
# Check spatial independence of folds using the default rho (N/A)
# Type ?check_folds for more details on the method
geo_diag <- check_folds(folds, plot = TRUE)
print(geo_diag)

# Plot results
plot(geo_diag) 

```

As the results illustrates, the minimum distance between points within a specific block (or fold) and points within its nearest block (i.e., the inter-block gap) is approximately 42 km in average. This indicates that there is no contiguous spatial folds from the selected blocking strategy, thereby supporting the hypothesis of no *block leakage*.

* **Folds diagnostics in the environmental space**

Another crucial aspect of blocked cross-validation strategy is to ensure that validation metrics reflect the model's ability to generalise across the species' niche, rather than its proximity to training data. The analysis of spatial folds in the environmental space can allow this hypothesis to be assessed as nearly met before proceeding with the modelling process.

```{r warning=FALSE,message=FALSE}
# Check environmental balance of folds
set.seed(42)  # set this for background sample reproducibility
env_diag <- check_env_balance(folds,
                              covariates = r,
                              n_background = 5000
                              )
print(env_diag)

```

```{r env-diag, fig.width = 6, fig.height = 4, out.width = "100%"}
# Plot outputs
plot(env_diag)

```

As illustrated by the outputs, the *Schoener D* metric is greater than 0.6 for both covariates. This indicates that spatial folds exhibit significant overlap with the background area. Additionally, the p-value resulting from comparing the median values of the variables across the folds is greater than 0.05. This suggests that the environmental variables do not differ significantly between the blocks. Consequently, it can be hypothesised that the spatial blocks are environmentally representative and may be robust for model prediction and generalisation.

* **Combined analysis**

It is possible to combine both types of fold diagnostics in order to draw a unified conclusion. However, it should be noted that the applicability of both diagnostic tools is not universal across all the spatial blocking strategies covered in the package. Therefore, the most appropriate block diagnostic tool may be contingent on the selected blocking scheme.

```{r }
# Combined diagnostics
summarise_fold_diagnostics(geo_diag, env_diag)

```

* **Mixture of continuous and categorical variables**

In practical application, we may have a mixture of continuous and categorical covariates (e.g. land cover). In this scenario, the *Schoener D* metric cannot be calculated for the categorical variable. The p-value for this variable is derived from the Chi-square test based on the Monte Carlo approximation instead of the Kruskal Wallis test used for the continuous variables.

```{r warning=FALSE,message=FALSE}
# Continuous (temperature) and categorical (land cover) variables
set.seed(42)

r_temp <- rast(ben_sf, nrow = 100, ncol = 100, val = runif(10000, 15, 25))
r_land <- rast(ben_sf, nrow = 100, ncol = 100, val = sample(1:4, 10000, TRUE))
levels(r_land) <- data.frame(ID = 1:4, cover = c("Forest", "Grass", "Urban", "Water"))
env_stack <- c(r_temp, r_land)
names(env_stack) <- c("temperature", "land_use")

# Run the test with 5000 background cells 
env_mixed <- check_env_balance(
  folds,
  covariates = env_stack,
  n_background = 5000,
  plot_type = "boxplot"
)

print(env_mixed)
```

```{r env-cat, fig.width = 6, fig.height = 4, out.width = "100%"}
# Plot outputs
plot(env_mixed)

```

# Data Extraction for Modelling

Once spatial folds are created, one can extract the data and see how it looks like right 
before it goes into a modelling tool like inlabru. You can access both 'train' and 'test' sets and their corresponding datasets as follows:

```{r }
# Extract fold 1
splits_1 <- extract_fold(folds, fold = 1)

# Accessing the training and testing sets for the "Presence" source
head(splits_1$train$Presence)

head(splits_1$test$Presence)
```

# Conclusion

Congratulations! You have successfully fused multi-source biodiversity data and generated spatially independent partitions for robust model validation. By using `create_folds()` and appropriate folds' diagnostic tools, you've ensured that your model evaluation will account for spatial autocorrelation, providing a more realistic estimate of predictive performance. 

The `isdmtools` journey continues with model fitting and comprehensive evaluation. Depending on your needs, we recommend the following paths:

- *Model Fitting*: Use the training data extracted via `extract_fold()` to fit your models using modelling engines like inlabru, PointedSDMs, or standard generalised additive mixed models (GAMMs) tools which can support multisource spatial data.
- *Integrated Evaluation*: Once predictions are obtained, evaluate the models and analyse the outputs.

The advanced guide on [ISDM Evaluation Workflow](isdm-workflow.html) covers model building with external tools, and the use of the use of `isdmtools` to perform model evaluation, suitability analysis and mapping.

# References
